{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4532039,"sourceType":"datasetVersion","datasetId":2579480}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n\nWe will tackle this problem in 3 parts:\n1. Pytorch Dataset\n2. Pytorch Model\n3. Pytorch Training Loop\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import torch #generic package\nimport torch.nn as nn #neural networks\nimport torch.nn.functional as F #activation functions\nimport torch.optim as optim #optimizer\n\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision.transforms as transforms #for standardizing input resolution\nfrom torchvision.datasets import ImageFolder #automatially infers the class from the title of the subdirectories\n\n#import timm #contains image models NOT GONNA USE BC OF BS kaggle download permissions\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:52:06.011268Z","iopub.execute_input":"2023-10-07T19:52:06.011633Z","iopub.status.idle":"2023-10-07T19:52:09.68773Z","shell.execute_reply.started":"2023-10-07T19:52:06.011603Z","shell.execute_reply":"2023-10-07T19:52:09.686644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"class PlayingCardDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        #here we give the init() a transform to apply to images as they are loaded in\n        self.data = ImageFolder(data_dir, transform=transform)\n        #we are outsourcing labelling and standardizing resolution \n        #to the ImageFolder class, which infers class labels from\n        #names of subdirectories of the data_dir and applies\n        #a transform to them automatically\n        #note: ImageFolder() returns an image and a class\n    \n    def __len__(self):\n        return len(self.data) #so that the rest of the pipeline knows how much data there is\n    \n    def __getitem__(self, idx):\n        #if you wanted to do preprocessing only when each individual\n        #example was accessed, you would do it here\n        return self.data[idx]\n        #getitem implements accessing an element via [] notation\n        \n    ###NONESSENTIAL, just for convenience--see the class labels in dataset\n    @property #TODO understand decorators and properties\n    def classes(self):\n        return self.data.classes\n        ","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:52:12.349039Z","iopub.execute_input":"2023-10-07T19:52:12.349523Z","iopub.status.idle":"2023-10-07T19:52:12.355573Z","shell.execute_reply.started":"2023-10-07T19:52:12.349493Z","shell.execute_reply":"2023-10-07T19:52:12.3545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make sure Dataset works","metadata":{}},{"cell_type":"code","source":"trial_dataset = PlayingCardDataset(\n    data_dir= '/kaggle/input/cards-image-datasetclassification/train'\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:52:15.853659Z","iopub.execute_input":"2023-10-07T19:52:15.853995Z","iopub.status.idle":"2023-10-07T19:52:18.050625Z","shell.execute_reply.started":"2023-10-07T19:52:15.853968Z","shell.execute_reply":"2023-10-07T19:52:18.049624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(trial_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:52:19.711153Z","iopub.execute_input":"2023-10-07T19:52:19.711691Z","iopub.status.idle":"2023-10-07T19:52:19.71805Z","shell.execute_reply.started":"2023-10-07T19:52:19.711661Z","shell.execute_reply":"2023-10-07T19:52:19.717167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, label = trial_dataset[6000] #the ImageFolder returns a tuple\nprint(label) #note: there are 53 different class including joker\nimage","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:52:24.203257Z","iopub.execute_input":"2023-10-07T19:52:24.204001Z","iopub.status.idle":"2023-10-07T19:52:24.243055Z","shell.execute_reply.started":"2023-10-07T19:52:24.203969Z","shell.execute_reply":"2023-10-07T19:52:24.242214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ImageFolder automatically encodes the classes as numbers\n#it would be nice to know how the numbers map to names\n\n#trial_dataset.data is an ImageDataset, and has a\n#class_to_idx attribute which is a dictionary\n#that holds this info\nfor k, v in trial_dataset.data.class_to_idx.items():\n    print(f\"{k}: {v}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:52:27.47668Z","iopub.execute_input":"2023-10-07T19:52:27.477034Z","iopub.status.idle":"2023-10-07T19:52:27.483437Z","shell.execute_reply.started":"2023-10-07T19:52:27.477008Z","shell.execute_reply":"2023-10-07T19:52:27.482494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#all inputs to a network need to be an equal size tensor, \n#so let's implement the resizing and then turn an image to a tensor\n\ntransform = transforms.Compose([\n    transforms.Resize([128, 128]),\n    transforms.ToTensor(),\n])\n\n#create official training set\ndata_dir = '/kaggle/input/cards-image-datasetclassification/train'\ntrain_dataset = PlayingCardDataset(data_dir, transform)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:52:32.66695Z","iopub.execute_input":"2023-10-07T19:52:32.667281Z","iopub.status.idle":"2023-10-07T19:52:32.733245Z","shell.execute_reply.started":"2023-10-07T19:52:32.667255Z","shell.execute_reply":"2023-10-07T19:52:32.732135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's see what it looks like\nimage, _ = train_dataset[0]\nimage #3 x 128 x 128, 128 grid for each color channel","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:52:38.330295Z","iopub.execute_input":"2023-10-07T19:52:38.331002Z","iopub.status.idle":"2023-10-07T19:52:38.439438Z","shell.execute_reply.started":"2023-10-07T19:52:38.330969Z","shell.execute_reply":"2023-10-07T19:52:38.438521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# iterate over dataset\nfor image, label in train_dataset: #note: dataset is an iterable\n    break\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:52:40.630595Z","iopub.execute_input":"2023-10-07T19:52:40.630921Z","iopub.status.idle":"2023-10-07T19:52:40.641463Z","shell.execute_reply.started":"2023-10-07T19:52:40.630896Z","shell.execute_reply":"2023-10-07T19:52:40.640297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"batch_size = 32\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n#shuffling is best practice\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:52:51.45035Z","iopub.execute_input":"2023-10-07T19:52:51.451039Z","iopub.status.idle":"2023-10-07T19:52:51.455754Z","shell.execute_reply.started":"2023-10-07T19:52:51.451009Z","shell.execute_reply":"2023-10-07T19:52:51.454802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DataLoader is an iterable that returns a batch as every element\n#gives both the inputs and labels\nfor images, labels in train_dataloader:\n    break","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:52:55.394389Z","iopub.execute_input":"2023-10-07T19:52:55.394766Z","iopub.status.idle":"2023-10-07T19:52:55.649762Z","shell.execute_reply.started":"2023-10-07T19:52:55.394739Z","shell.execute_reply":"2023-10-07T19:52:55.648813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images.shape, labels.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:52:58.168268Z","iopub.execute_input":"2023-10-07T19:52:58.168943Z","iopub.status.idle":"2023-10-07T19:52:58.175555Z","shell.execute_reply.started":"2023-10-07T19:52:58.16891Z","shell.execute_reply":"2023-10-07T19:52:58.174245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:52:59.636786Z","iopub.execute_input":"2023-10-07T19:52:59.637129Z","iopub.status.idle":"2023-10-07T19:52:59.644233Z","shell.execute_reply.started":"2023-10-07T19:52:59.637102Z","shell.execute_reply":"2023-10-07T19:52:59.643311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CardClassifier(nn.Module): #inherit from nn.Module\n    def __init__(self, num_classes):\n        #where we define the parts of the model\n        \n        #call __init__() on super class to inherit methods from it\n        #TODO: understand what the arguments \n        super(CardClassifier, self).__init__()\n\n#         #we need the number of output classes to build the model, \n#         #so we pass it in\n        \n#         #let's pull in an image classifier\n#         self.base_model = timm.create_model('efficientnet_b0', pretrained=True)\n#         #this layer is used to taking in 3 x 128 x 128 images, spits out a single dense layer of 1280 neurons\n#         enet_out_size = 1280\n        \n#         #one note: this base model actually has a final layer we don't want to use\n#         #so we will configure an almost-complete version of it where we snip that off\n#         #we do it by using the nn.Sequential() constructor, which takes in \n#         #a list of layers and connects them into a model. \n#         #we get that list of layers by indexing through \n#         #base_model.children(), which gives the layers. then we \n#         #convert it to a list and unpack the elements to feed them \n#         #in as arguments to nn.Sequential\n#         self.truncated_base_model = nn.Sequential(*list(self.base_model.children()[:-1]))\n        \n#         #add a final fully connected layer that maps the output of the truncated model to classes\n#         self.classification_layer = nn.Linear(enet_out_size, num_classes)\n        \n        #actually building from scratch\n        #idea: \n        #conv layer with batch normalization that preserves size\n        #max pool \n        #conv layer \"\" \"\" \n        #max pool \n        \n        #flatten it out\n        #linear down to 512\n        #linear down to number of classes\n        \n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, stride=1, padding=1) #gives 128*128*5 features\n        self.bn1 = nn.BatchNorm2d(5) #makes each 2d layer have mean zero, unit variance, input is number of channels\n        self.maxpool = nn.MaxPool2d(2,2) #stride = 2, so halves image size to 64x64, inputs are dimensions of kernel\n\n        #note: since this doesnt have weights, we can define one instance of this and use it multiple times\n        \n        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, stride=1, padding=1) #gives 64x64x10 features\n        self.bn2 = nn.BatchNorm2d(10) #we now have 10 channels\n        \n        #note: flattening will happen in training loop\n        self.linear1 = nn.Linear(32*32*10, 512) #in, out\n        self.classification = nn.Linear(512, num_classes)\n        return\n   \n    def forward(self, x):\n        #where we take in an example or a batch and return it\n        \n        #in comes a batch. we want to feed it through the truncated_base_model,\n        #then classification\n        \n#         #pass through base model\n#         x = self.truncated_base_model(x)\n#         #the truncated_base_model can take in batches of any size\n#         #and returns an output correspondingly. so it takes in \n#         #batch_size x 3 x 128 x 128 and therefore spits out\n#         #batch_size x 1280. then the final connected layer\n#         #takes in any batch size as well and gives corresponding output\n#         #so it takes in batch_size x 1280 and  outputs batch_size x num_classes\n        \n#         #note: idiomatic to keep ovewriting x throgh each nonterminal layer\n        \n#         output = self.classification_layer \n\n        #note: ReLU only happens after the normalization\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = F.relu(x)\n        x = self.maxpool(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = F.relu(x)\n        x = self.maxpool(x)\n        \n        #flatten x out so it can be passed into classifier\n        x = x.view(-1, 32*32*10) #the -1 infers the number of entries in the batch, an the 32*32*10 is the number of neurons in the linear layer\n        x = self.linear1(x)\n        x = self.classification(x)\n    \n        return x #note: pytorch loss functions take in logits, so we don't have to apply softmax\n        \n        \n        \n        \n        \n","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:53:10.554822Z","iopub.execute_input":"2023-10-07T19:53:10.555158Z","iopub.status.idle":"2023-10-07T19:53:10.565063Z","shell.execute_reply.started":"2023-10-07T19:53:10.55513Z","shell.execute_reply":"2023-10-07T19:53:10.563951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CardClassifier(num_classes=53)\nprint(str(model))","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:53:20.26612Z","iopub.execute_input":"2023-10-07T19:53:20.266464Z","iopub.status.idle":"2023-10-07T19:53:20.325182Z","shell.execute_reply.started":"2023-10-07T19:53:20.266415Z","shell.execute_reply":"2023-10-07T19:53:20.324169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_out = model(images)\nexample_out.shape # [batch_size, num_classes]","metadata":{"execution":{"iopub.status.busy":"2023-10-07T19:53:24.006355Z","iopub.execute_input":"2023-10-07T19:53:24.006763Z","iopub.status.idle":"2023-10-07T19:53:24.252357Z","shell.execute_reply.started":"2023-10-07T19:53:24.006737Z","shell.execute_reply":"2023-10-07T19:53:24.251376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss() #loss function is called criterion \n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n#adam takes in the model's parameters and learning rate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loss functions take in inputs and labels\n\ncriterion(example_out, labels)\n#gives a tensor containing the value of the loss\n\n#note: this will currently give an error because the ","metadata":{"execution":{"iopub.status.busy":"2023-10-07T21:12:15.234337Z","iopub.execute_input":"2023-10-07T21:12:15.234692Z","iopub.status.idle":"2023-10-07T21:12:15.775952Z","shell.execute_reply.started":"2023-10-07T21:12:15.234666Z","shell.execute_reply":"2023-10-07T21:12:15.774735Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#datasets require a transformation, so let's remake that first\n\ntransform = transforms.Compose([\n    transforms.Resize((128,128)),\n    transforms.ToTensor(),\n])\n\ntrain_dataset = PlayingCardDataset(data_dir='/kaggle/input/cards-image-datasetclassification/train', transform=transform)\nval_dataset = PlayingCardDataset(data_dir='/kaggle/input/cards-image-datasetclassification/valid', transform=transform)\ntest_dataset = PlayingCardDataset(data_dir='/kaggle/input/cards-image-datasetclassification/test', transform=transform)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=32)\ntest_dataloader = DataLoader(test_dataset, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2023-10-07T21:13:39.628066Z","iopub.execute_input":"2023-10-07T21:13:39.628427Z","iopub.status.idle":"2023-10-07T21:13:39.840184Z","shell.execute_reply.started":"2023-10-07T21:13:39.6284Z","shell.execute_reply":"2023-10-07T21:13:39.839241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#move training to GPU if possible\n#the way this works is you find out what device is possible\n#then in the loop manually move the model and data to the device\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nnum_epoch = 5\ntrain_losses, val_losses = [], []\n\nmodel = CardClassifier(num_classes=53)\nmodel.to(device) #put model on GPU\n\nfor epoch in range(num_epoch):\n    #set model to train mode TODO what does this mean\n    model.train()\n    running_loss = 0.0\n    \n    #feed each batch in\n    for images, labels in train_dataloader:\n        #put images, labels on GPU\n        images, labels = images.to(device), labels.to(device)\n        \n        #optimizer keeps track of the gradients of the model wrt each parameter\n        optimizer.zero_grad()\n        outputs = model(images) #calls forward on them\n        loss = criterion(outputs, labels)\n        \n        \n        #pytorch's autograd engine is 'listening' to all the operations that happen on tensors\n        #all the time and keeps track of how they relate to each other\n        #so it knows that loss is connected to the model weights\n        #by the fact that output was a function of the weights\n        #and loss is a function of the output. it knows this \n        #without us needing to write out the connection. it is just \n        #listening for backward() calls, at which point it updates\n        #all the params' gradients. \n        loss.backward() #computes gradients of each param wrt loss\n        \n        \n        #note: optimizer explicitly took in the model's params\n        #as arguments when it was initialized, so it is easy\n        #to understand how this updates the weights\n        optimizer.step() #actually changes parameters by the gradient\n        \n        \n        #at the end of the day you want to know the avg loss \n        #per training example, so we add up all the individual losses\n        #from each batch. then after we have gone through\n        #every batch, we will average it out and save the value\n        \n        #note: the loss is the AVG loss for the batch bc the default\n        #REDUCTION of pytorch losses is 'mean'\n        #so to get the total loss for the entire batch, you have to \n        #multiply by the size of the batch\n        #item() gets the value of the tensor, and images.size()\n        #gets the batch size\n        running_loss += loss.item() * images.size(0)\n        \n    #calc avg loss per example over entire training set and store\n    train_loss = running_loss / len(train_dataloader.dataset) #need to put.dataset--oterwise will give number of batches\n    train_losses.append(running_loss)\n    \n    \n    #also monitor the validation losses\n    model.eval() #TODO what does this do\n    running_val_loss = 0.0\n    with torch.no_grad(): #makes it so autograd does not automatically collect or deposit gradient info \n        #into tensors. here we don't call backward, so it's not strictly necessary,\n        #but it DOES speed things up bc torch is no longer paying any mind to the gradients\n        \n        \n        for images, labels in val_dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            running_val_loss += loss.item() * images.size(0)\n        val_loss = running_val_loss / len(val_dataloader.dataset)\n        val_losses.append(val_loss)\n        \n    #log errors\n    print(f\"Epoch: {epoch+1}/{num_epoch} -- Train loss: {train_loss}, Val loss: {val_loss}\")\n        \n    \n    #OKAY loss s not changing much\n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-10-07T21:15:44.669532Z","iopub.execute_input":"2023-10-07T21:15:44.669872Z","iopub.status.idle":"2023-10-07T21:17:12.342202Z","shell.execute_reply.started":"2023-10-07T21:15:44.669844Z","shell.execute_reply":"2023-10-07T21:17:12.341228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_losses, label='Training loss')\nplt.plot(val_losses, label='Validation loss')\nplt.legend()\nplt.title(\"Loss over epochs\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Bonus:** Evaluating the Results\n\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load and preprocess the image\ndef preprocess_image(image_path, transform):\n    image = Image.open(image_path).convert(\"RGB\")\n    return image, transform(image).unsqueeze(0)\n\n# Predict using the model\ndef predict(model, image_tensor, device):\n    model.eval()\n    with torch.no_grad():\n        image_tensor = image_tensor.to(device)\n        outputs = model(image_tensor)\n        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n    return probabilities.cpu().numpy().flatten()\n\n# Visualization\ndef visualize_predictions(original_image, probabilities, class_names):\n    fig, axarr = plt.subplots(1, 2, figsize=(14, 7))\n    \n    # Display image\n    axarr[0].imshow(original_image)\n    axarr[0].axis(\"off\")\n    \n    # Display predictions\n    axarr[1].barh(class_names, probabilities)\n    axarr[1].set_xlabel(\"Probability\")\n    axarr[1].set_title(\"Class Predictions\")\n    axarr[1].set_xlim(0, 1)\n\n    plt.tight_layout()\n    plt.show()\n\n# Example usage\ntest_image = \"/kaggle/input/cards-image-datasetclassification/test/five of diamonds/2.jpg\"\ntransform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor()\n])\n\noriginal_image, image_tensor = preprocess_image(test_image, transform)\nprobabilities = predict(model, image_tensor, device)\n\n# Assuming dataset.classes gives the class names\nclass_names = dataset.classes \nvisualize_predictions(original_image, probabilities, class_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\ntest_images = glob('../input/cards-image-datasetclassification/test/*/*')\ntest_examples = np.random.choice(test_images, 10)\n\nfor example in test_examples:\n    original_image, image_tensor = preprocess_image(example, transform)\n    probabilities = predict(model, image_tensor, device)\n\n    # Assuming dataset.classes gives the class names\n    class_names = dataset.classes \n    visualize_predictions(original_image, probabilities, class_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Todo\n\n- Calculate the accuracy of our model on the validation and test set.","metadata":{}}]}